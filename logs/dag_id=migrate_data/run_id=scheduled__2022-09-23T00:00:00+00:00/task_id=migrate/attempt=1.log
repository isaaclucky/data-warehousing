[2022-09-24T06:01:18.730+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:01:18.745+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:01:18.745+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:01:18.745+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T06:01:18.746+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:01:18.768+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T06:01:18.775+0000] {standard_task_runner.py:54} INFO - Started process 124 to run task
[2022-09-24T06:01:18.779+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmpqdudn4dg']
[2022-09-24T06:01:18.780+0000] {standard_task_runner.py:83} INFO - Job 16: Subtask migrate
[2022-09-24T06:01:18.781+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T06:01:20.475+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host 6b141fc40122
[2022-09-24T06:01:20.580+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T06:01:20.612+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 32, in migrate_data
    echo=True, future=True)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 309, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 534, in create_engine
    entrypoint = u._get_entrypoint()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/url.py", line 645, in _get_entrypoint
    cls = registry.load(name)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 344, in load
    "Can't load plugin: %s:%s" % (self.group, name)
sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres.psycopg2
[2022-09-24T06:01:20.627+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T060118, end_date=20220924T060120
[2022-09-24T06:01:20.648+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/email.py:120: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2022-09-24T06:01:20.649+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:01:20.649+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:01:20.659+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:01:20.659+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:01:20.660+0000] {taskinstance.py:1914} ERROR - Failed to send email to: ['isaaclucky88@gmail.com']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1457, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1603, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1664, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 32, in migrate_data
    echo=True, future=True)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 309, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 534, in create_engine
    entrypoint = u._get_entrypoint()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/url.py", line 645, in _get_entrypoint
    cls = registry.load(name)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 344, in load
    "Can't load plugin: %s:%s" % (self.group, name)
sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres.psycopg2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2311, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1912, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2313, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2022-09-24T06:01:20.679+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 16 for task migrate (Can't load plugin: sqlalchemy.dialects:postgres.psycopg2; 124)
[2022-09-24T06:01:20.717+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-09-24T06:01:20.747+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-24T06:05:35.863+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:05:35.877+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:05:35.877+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:05:35.877+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T06:05:35.877+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:05:35.896+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T06:05:35.902+0000] {standard_task_runner.py:54} INFO - Started process 321 to run task
[2022-09-24T06:05:35.906+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmp339hudw3']
[2022-09-24T06:05:35.906+0000] {standard_task_runner.py:83} INFO - Job 18: Subtask migrate
[2022-09-24T06:05:35.907+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T06:05:36.415+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host 6b141fc40122
[2022-09-24T06:05:36.534+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T06:05:36.578+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 32, in migrate_data
    echo=True, future=True)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 309, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 534, in create_engine
    entrypoint = u._get_entrypoint()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/url.py", line 645, in _get_entrypoint
    cls = registry.load(name)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 344, in load
    "Can't load plugin: %s:%s" % (self.group, name)
sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres.psycopg2
[2022-09-24T06:05:36.591+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T060535, end_date=20220924T060536
[2022-09-24T06:05:36.612+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/email.py:120: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2022-09-24T06:05:36.613+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:05:36.613+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:05:36.623+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:05:36.624+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:05:36.625+0000] {taskinstance.py:1914} ERROR - Failed to send email to: ['isaaclucky88@gmail.com']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1457, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1603, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1664, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 32, in migrate_data
    echo=True, future=True)
  File "<string>", line 2, in create_engine
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py", line 309, in warned
    return fn(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 534, in create_engine
    entrypoint = u._get_entrypoint()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/url.py", line 645, in _get_entrypoint
    cls = registry.load(name)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 344, in load
    "Can't load plugin: %s:%s" % (self.group, name)
sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres.psycopg2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2311, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1912, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2313, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2022-09-24T06:05:36.657+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 18 for task migrate (Can't load plugin: sqlalchemy.dialects:postgres.psycopg2; 321)
[2022-09-24T06:05:36.719+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-09-24T06:05:36.780+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-24T06:35:59.632+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:35:59.667+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T06:35:59.667+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:35:59.668+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T06:35:59.668+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T06:35:59.734+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T06:35:59.749+0000] {standard_task_runner.py:54} INFO - Started process 191 to run task
[2022-09-24T06:35:59.756+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmptx5sw_be']
[2022-09-24T06:35:59.757+0000] {standard_task_runner.py:83} INFO - Job 33: Subtask migrate
[2022-09-24T06:35:59.759+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T06:36:00.958+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host 6b141fc40122
[2022-09-24T06:36:01.319+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T06:36:01.330+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  return func(*args, **kwargs)

[2022-09-24T06:36:01.360+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.
  return _read(filepath_or_buffer, kwds)

[2022-09-24T06:36:01.393+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<start migrating data>>>>>>>>>>>>>>
[2022-09-24T06:36:01.408+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5434 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5434 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 36, in migrate_data
    df.to_sql(db_table, con=engine, if_exists='replace',index_label='id')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1783, in has_table
    insp = sa.inspect(self.connectable)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/inspection.py", line 64, in inspect
    ret = reg(subject)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 182, in _engine_insp
    return Inspector._construct(Inspector._init_engine, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 117, in _construct
    init(self, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 128, in _init_engine
    engine.connect().close()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3247, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2101, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5434 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5434 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-09-24T06:36:01.477+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T063559, end_date=20220924T063601
[2022-09-24T06:36:01.522+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/email.py:120: RemovedInAirflow3Warning: Fetching SMTP credentials from configuration variables will be deprecated in a future release. Please set credentials using a connection instead.
  send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)

[2022-09-24T06:36:01.522+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:36:01.522+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:36:01.536+0000] {configuration.py:569} WARNING - section/key [smtp/smtp_user] not found in config
[2022-09-24T06:36:01.537+0000] {email.py:229} INFO - Email alerting: attempt 1
[2022-09-24T06:36:01.537+0000] {taskinstance.py:1914} ERROR - Failed to send email to: ['isaaclucky88@gmail.com']
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5434 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5434 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1457, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1603, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1664, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/migrate.py", line 36, in migrate_data
    df.to_sql(db_table, con=engine, if_exists='replace',index_label='id')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1783, in has_table
    insp = sa.inspect(self.connectable)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/inspection.py", line 64, in inspect
    ret = reg(subject)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 182, in _engine_insp
    return Inspector._construct(Inspector._init_engine, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 117, in _construct
    init(self, bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/reflection.py", line 128, in _init_engine
    engine.connect().close()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3247, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2101, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5434 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5434 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2311, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1912, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2313, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 72, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 120, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 231, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 265, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
OSError: [Errno 99] Cannot assign requested address
[2022-09-24T06:36:01.595+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 33 for task migrate ((psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5434 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5434 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/14/e3q8); 191)
[2022-09-24T06:36:01.651+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-09-24T06:36:01.691+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-24T09:53:42.371+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T09:53:42.389+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T09:53:42.390+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T09:53:42.390+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T09:53:42.390+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T09:53:42.411+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T09:53:42.420+0000] {standard_task_runner.py:54} INFO - Started process 345 to run task
[2022-09-24T09:53:42.424+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmpd61j__rs']
[2022-09-24T09:53:42.425+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask migrate
[2022-09-24T09:53:42.426+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T09:53:43.262+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host 4b5cbff5ff8c
[2022-09-24T09:53:43.370+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T09:53:43.373+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  return func(*args, **kwargs)

[2022-09-24T09:53:43.383+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.
  return _read(filepath_or_buffer, kwds)

[2022-09-24T09:53:43.391+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<start migrating data>>>>>>>>>>>>>>
[2022-09-24T09:53:43.402+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,402 INFO sqlalchemy.engine.Engine select pg_catalog.version()
[2022-09-24T09:53:43.402+0000] {log.py:117} INFO - select pg_catalog.version()
[2022-09-24T09:53:43.403+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,403 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T09:53:43.403+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T09:53:43.404+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,404 INFO sqlalchemy.engine.Engine select current_schema()
[2022-09-24T09:53:43.404+0000] {log.py:117} INFO - select current_schema()
[2022-09-24T09:53:43.404+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,404 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T09:53:43.404+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T09:53:43.405+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,405 INFO sqlalchemy.engine.Engine show standard_conforming_strings
[2022-09-24T09:53:43.405+0000] {log.py:117} INFO - show standard_conforming_strings
[2022-09-24T09:53:43.406+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,406 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T09:53:43.406+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T09:53:43.408+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,408 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.408+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.408+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,408 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T09:53:43.408+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T09:53:43.408+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,408 INFO sqlalchemy.engine.Engine [generated in 0.00080s] {'name': 'traffic_data'}
[2022-09-24T09:53:43.408+0000] {log.py:117} INFO - [generated in 0.00080s] {'name': 'traffic_data'}
[2022-09-24T09:53:43.410+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,410 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T09:53:43.410+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T09:53:43.411+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,411 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.411+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.412+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,412 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T09:53:43.412+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T09:53:43.412+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,412 INFO sqlalchemy.engine.Engine [cached since 0.004562s ago] {'name': 'traffic_data'}
[2022-09-24T09:53:43.412+0000] {log.py:117} INFO - [cached since 0.004562s ago] {'name': 'traffic_data'}
[2022-09-24T09:53:43.414+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,414 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T09:53:43.414+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T09:53:43.415+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,415 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.415+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.416+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,416 INFO sqlalchemy.engine.Engine SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T09:53:43.416+0000] {log.py:117} INFO - SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T09:53:43.416+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,416 INFO sqlalchemy.engine.Engine [generated in 0.00123s] {'schema': 'public'}
[2022-09-24T09:53:43.416+0000] {log.py:117} INFO - [generated in 0.00123s] {'schema': 'public'}
[2022-09-24T09:53:43.419+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,419 INFO sqlalchemy.engine.Engine 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
[2022-09-24T09:53:43.419+0000] {log.py:117} INFO - 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
        
[2022-09-24T09:53:43.420+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,420 INFO sqlalchemy.engine.Engine [generated in 0.00049s] {'table_name': 'traffic_data'}
[2022-09-24T09:53:43.420+0000] {log.py:117} INFO - [generated in 0.00049s] {'table_name': 'traffic_data'}
[2022-09-24T09:53:43.422+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,421 INFO sqlalchemy.engine.Engine 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
[2022-09-24T09:53:43.421+0000] {log.py:117} INFO - 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
        
[2022-09-24T09:53:43.422+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,422 INFO sqlalchemy.engine.Engine [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.422+0000] {log.py:117} INFO - [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.426+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,425 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
[2022-09-24T09:53:43.425+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
        
[2022-09-24T09:53:43.426+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,426 INFO sqlalchemy.engine.Engine [generated in 0.00048s] {}
[2022-09-24T09:53:43.426+0000] {log.py:117} INFO - [generated in 0.00048s] {}
[2022-09-24T09:53:43.428+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,428 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T09:53:43.428+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T09:53:43.428+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,428 INFO sqlalchemy.engine.Engine [generated in 0.00057s] {}
[2022-09-24T09:53:43.428+0000] {log.py:117} INFO - [generated in 0.00057s] {}
[2022-09-24T09:53:43.432+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,432 INFO sqlalchemy.engine.Engine 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
[2022-09-24T09:53:43.432+0000] {log.py:117} INFO - 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
            
[2022-09-24T09:53:43.433+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,433 INFO sqlalchemy.engine.Engine [generated in 0.00052s] {'table_oid': 16983}
[2022-09-24T09:53:43.433+0000] {log.py:117} INFO - [generated in 0.00052s] {'table_oid': 16983}
[2022-09-24T09:53:43.435+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,434 INFO sqlalchemy.engine.Engine 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
[2022-09-24T09:53:43.434+0000] {log.py:117} INFO - 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
        
[2022-09-24T09:53:43.435+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,435 INFO sqlalchemy.engine.Engine [generated in 0.00047s] {'table_oid': 16983}
[2022-09-24T09:53:43.435+0000] {log.py:117} INFO - [generated in 0.00047s] {'table_oid': 16983}
[2022-09-24T09:53:43.437+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,437 INFO sqlalchemy.engine.Engine 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
[2022-09-24T09:53:43.437+0000] {log.py:117} INFO - 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
        
[2022-09-24T09:53:43.437+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,437 INFO sqlalchemy.engine.Engine [generated in 0.00047s] {'table': 16983}
[2022-09-24T09:53:43.437+0000] {log.py:117} INFO - [generated in 0.00047s] {'table': 16983}
[2022-09-24T09:53:43.440+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,439 INFO sqlalchemy.engine.Engine 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
[2022-09-24T09:53:43.439+0000] {log.py:117} INFO - 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
            
[2022-09-24T09:53:43.440+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,440 INFO sqlalchemy.engine.Engine [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.440+0000] {log.py:117} INFO - [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.443+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,443 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
[2022-09-24T09:53:43.443+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
        
[2022-09-24T09:53:43.444+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,444 INFO sqlalchemy.engine.Engine [generated in 0.00053s] {'table_oid': 16983}
[2022-09-24T09:53:43.444+0000] {log.py:117} INFO - [generated in 0.00053s] {'table_oid': 16983}
[2022-09-24T09:53:43.446+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,446 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
[2022-09-24T09:53:43.446+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
        
[2022-09-24T09:53:43.446+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,446 INFO sqlalchemy.engine.Engine [generated in 0.00055s] {'table_oid': 16983}
[2022-09-24T09:53:43.446+0000] {log.py:117} INFO - [generated in 0.00055s] {'table_oid': 16983}
[2022-09-24T09:53:43.447+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,447 INFO sqlalchemy.engine.Engine 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
[2022-09-24T09:53:43.447+0000] {log.py:117} INFO - 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
        
[2022-09-24T09:53:43.448+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,448 INFO sqlalchemy.engine.Engine [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.448+0000] {log.py:117} INFO - [generated in 0.00049s] {'table_oid': 16983}
[2022-09-24T09:53:43.449+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,449 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T09:53:43.449+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T09:53:43.450+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,450 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.450+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.450+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,450 INFO sqlalchemy.engine.Engine 
DROP TABLE traffic_data
[2022-09-24T09:53:43.450+0000] {log.py:117} INFO - 
DROP TABLE traffic_data
[2022-09-24T09:53:43.451+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,451 INFO sqlalchemy.engine.Engine [no key 0.00037s] {}
[2022-09-24T09:53:43.451+0000] {log.py:117} INFO - [no key 0.00037s] {}
[2022-09-24T09:53:43.453+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,453 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T09:53:43.453+0000] {log.py:117} INFO - COMMIT
[2022-09-24T09:53:43.459+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,458 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.458+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.460+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,460 INFO sqlalchemy.engine.Engine 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)
[2022-09-24T09:53:43.460+0000] {log.py:117} INFO - 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)


[2022-09-24T09:53:43.461+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,461 INFO sqlalchemy.engine.Engine [no key 0.00047s] {}
[2022-09-24T09:53:43.461+0000] {log.py:117} INFO - [no key 0.00047s] {}
[2022-09-24T09:53:43.467+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,467 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T09:53:43.467+0000] {log.py:117} INFO - CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T09:53:43.468+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,468 INFO sqlalchemy.engine.Engine [no key 0.00046s] {}
[2022-09-24T09:53:43.468+0000] {log.py:117} INFO - [no key 0.00046s] {}
[2022-09-24T09:53:43.470+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,470 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T09:53:43.470+0000] {log.py:117} INFO - COMMIT
[2022-09-24T09:53:43.476+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,476 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T09:53:43.476+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T09:53:43.479+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,478 INFO sqlalchemy.engine.Engine INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T09:53:43.478+0000] {log.py:117} INFO - INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T09:53:43.479+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,479 INFO sqlalchemy.engine.Engine [generated in 0.00112s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T09:53:43.479+0000] {log.py:117} INFO - [generated in 0.00112s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T09:53:43.481+0000] {logging_mixin.py:117} INFO - 2022-09-24 09:53:43,481 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T09:53:43.481+0000] {log.py:117} INFO - COMMIT
[2022-09-24T09:53:43.482+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<<<<<<<<<<completed>>>>>>>>>>>>>>>>
[2022-09-24T09:53:43.482+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-09-24T09:53:43.499+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T095342, end_date=20220924T095343
[2022-09-24T09:53:43.558+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-09-24T09:53:43.593+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-09-24T11:23:42.718+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T11:23:42.736+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T11:23:42.736+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T11:23:42.737+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T11:23:42.737+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T11:23:42.759+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T11:23:42.765+0000] {standard_task_runner.py:54} INFO - Started process 373 to run task
[2022-09-24T11:23:42.769+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmpa6btuo5h']
[2022-09-24T11:23:42.770+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask migrate
[2022-09-24T11:23:42.771+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T11:23:43.762+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host d3bad4f46616
[2022-09-24T11:23:43.864+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T11:23:43.866+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  return func(*args, **kwargs)

[2022-09-24T11:23:43.879+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.
  return _read(filepath_or_buffer, kwds)

[2022-09-24T11:23:43.893+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<start migrating data>>>>>>>>>>>>>>
[2022-09-24T11:23:43.904+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,904 INFO sqlalchemy.engine.Engine select pg_catalog.version()
[2022-09-24T11:23:43.904+0000] {log.py:117} INFO - select pg_catalog.version()
[2022-09-24T11:23:43.905+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,904 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T11:23:43.904+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T11:23:43.906+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,906 INFO sqlalchemy.engine.Engine select current_schema()
[2022-09-24T11:23:43.906+0000] {log.py:117} INFO - select current_schema()
[2022-09-24T11:23:43.906+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,906 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T11:23:43.906+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T11:23:43.907+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,907 INFO sqlalchemy.engine.Engine show standard_conforming_strings
[2022-09-24T11:23:43.907+0000] {log.py:117} INFO - show standard_conforming_strings
[2022-09-24T11:23:43.907+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,907 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T11:23:43.907+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T11:23:43.910+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,910 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.910+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.910+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,910 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T11:23:43.910+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T11:23:43.910+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,910 INFO sqlalchemy.engine.Engine [generated in 0.00081s] {'name': 'traffic_data'}
[2022-09-24T11:23:43.910+0000] {log.py:117} INFO - [generated in 0.00081s] {'name': 'traffic_data'}
[2022-09-24T11:23:43.912+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,912 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T11:23:43.912+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T11:23:43.913+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,913 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.913+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.913+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,913 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T11:23:43.913+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T11:23:43.913+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,913 INFO sqlalchemy.engine.Engine [cached since 0.004015s ago] {'name': 'traffic_data'}
[2022-09-24T11:23:43.913+0000] {log.py:117} INFO - [cached since 0.004015s ago] {'name': 'traffic_data'}
[2022-09-24T11:23:43.915+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,915 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T11:23:43.915+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T11:23:43.916+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,916 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.916+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.916+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,916 INFO sqlalchemy.engine.Engine SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T11:23:43.916+0000] {log.py:117} INFO - SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T11:23:43.917+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,917 INFO sqlalchemy.engine.Engine [generated in 0.00080s] {'schema': 'public'}
[2022-09-24T11:23:43.917+0000] {log.py:117} INFO - [generated in 0.00080s] {'schema': 'public'}
[2022-09-24T11:23:43.919+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,919 INFO sqlalchemy.engine.Engine 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
[2022-09-24T11:23:43.919+0000] {log.py:117} INFO - 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
        
[2022-09-24T11:23:43.920+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,920 INFO sqlalchemy.engine.Engine [generated in 0.00051s] {'table_name': 'traffic_data'}
[2022-09-24T11:23:43.920+0000] {log.py:117} INFO - [generated in 0.00051s] {'table_name': 'traffic_data'}
[2022-09-24T11:23:43.921+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,921 INFO sqlalchemy.engine.Engine 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
[2022-09-24T11:23:43.921+0000] {log.py:117} INFO - 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
        
[2022-09-24T11:23:43.922+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,922 INFO sqlalchemy.engine.Engine [generated in 0.00048s] {'table_oid': 16999}
[2022-09-24T11:23:43.922+0000] {log.py:117} INFO - [generated in 0.00048s] {'table_oid': 16999}
[2022-09-24T11:23:43.925+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,925 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
[2022-09-24T11:23:43.925+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
        
[2022-09-24T11:23:43.926+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,926 INFO sqlalchemy.engine.Engine [generated in 0.00044s] {}
[2022-09-24T11:23:43.926+0000] {log.py:117} INFO - [generated in 0.00044s] {}
[2022-09-24T11:23:43.927+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,927 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T11:23:43.927+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T11:23:43.928+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,928 INFO sqlalchemy.engine.Engine [generated in 0.00045s] {}
[2022-09-24T11:23:43.928+0000] {log.py:117} INFO - [generated in 0.00045s] {}
[2022-09-24T11:23:43.931+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,931 INFO sqlalchemy.engine.Engine 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
[2022-09-24T11:23:43.931+0000] {log.py:117} INFO - 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
            
[2022-09-24T11:23:43.932+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,932 INFO sqlalchemy.engine.Engine [generated in 0.00047s] {'table_oid': 16999}
[2022-09-24T11:23:43.932+0000] {log.py:117} INFO - [generated in 0.00047s] {'table_oid': 16999}
[2022-09-24T11:23:43.934+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,934 INFO sqlalchemy.engine.Engine 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
[2022-09-24T11:23:43.934+0000] {log.py:117} INFO - 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
        
[2022-09-24T11:23:43.934+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,934 INFO sqlalchemy.engine.Engine [generated in 0.00045s] {'table_oid': 16999}
[2022-09-24T11:23:43.934+0000] {log.py:117} INFO - [generated in 0.00045s] {'table_oid': 16999}
[2022-09-24T11:23:43.936+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,936 INFO sqlalchemy.engine.Engine 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
[2022-09-24T11:23:43.936+0000] {log.py:117} INFO - 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
        
[2022-09-24T11:23:43.936+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,936 INFO sqlalchemy.engine.Engine [generated in 0.00045s] {'table': 16999}
[2022-09-24T11:23:43.936+0000] {log.py:117} INFO - [generated in 0.00045s] {'table': 16999}
[2022-09-24T11:23:43.938+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,938 INFO sqlalchemy.engine.Engine 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
[2022-09-24T11:23:43.938+0000] {log.py:117} INFO - 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
            
[2022-09-24T11:23:43.939+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,939 INFO sqlalchemy.engine.Engine [generated in 0.00051s] {'table_oid': 16999}
[2022-09-24T11:23:43.939+0000] {log.py:117} INFO - [generated in 0.00051s] {'table_oid': 16999}
[2022-09-24T11:23:43.942+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,942 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
[2022-09-24T11:23:43.942+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
        
[2022-09-24T11:23:43.942+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,942 INFO sqlalchemy.engine.Engine [generated in 0.00048s] {'table_oid': 16999}
[2022-09-24T11:23:43.942+0000] {log.py:117} INFO - [generated in 0.00048s] {'table_oid': 16999}
[2022-09-24T11:23:43.944+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,944 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
[2022-09-24T11:23:43.944+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
        
[2022-09-24T11:23:43.944+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,944 INFO sqlalchemy.engine.Engine [generated in 0.00044s] {'table_oid': 16999}
[2022-09-24T11:23:43.944+0000] {log.py:117} INFO - [generated in 0.00044s] {'table_oid': 16999}
[2022-09-24T11:23:43.945+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,945 INFO sqlalchemy.engine.Engine 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
[2022-09-24T11:23:43.945+0000] {log.py:117} INFO - 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
        
[2022-09-24T11:23:43.946+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,946 INFO sqlalchemy.engine.Engine [generated in 0.00044s] {'table_oid': 16999}
[2022-09-24T11:23:43.946+0000] {log.py:117} INFO - [generated in 0.00044s] {'table_oid': 16999}
[2022-09-24T11:23:43.946+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,946 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T11:23:43.946+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T11:23:43.947+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,947 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.947+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.948+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,948 INFO sqlalchemy.engine.Engine 
DROP TABLE traffic_data
[2022-09-24T11:23:43.948+0000] {log.py:117} INFO - 
DROP TABLE traffic_data
[2022-09-24T11:23:43.948+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,948 INFO sqlalchemy.engine.Engine [no key 0.00037s] {}
[2022-09-24T11:23:43.948+0000] {log.py:117} INFO - [no key 0.00037s] {}
[2022-09-24T11:23:43.950+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,950 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T11:23:43.950+0000] {log.py:117} INFO - COMMIT
[2022-09-24T11:23:43.955+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,955 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.955+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.957+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,957 INFO sqlalchemy.engine.Engine 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)
[2022-09-24T11:23:43.957+0000] {log.py:117} INFO - 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)


[2022-09-24T11:23:43.957+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,957 INFO sqlalchemy.engine.Engine [no key 0.00041s] {}
[2022-09-24T11:23:43.957+0000] {log.py:117} INFO - [no key 0.00041s] {}
[2022-09-24T11:23:43.961+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,961 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T11:23:43.961+0000] {log.py:117} INFO - CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T11:23:43.962+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,962 INFO sqlalchemy.engine.Engine [no key 0.00041s] {}
[2022-09-24T11:23:43.962+0000] {log.py:117} INFO - [no key 0.00041s] {}
[2022-09-24T11:23:43.964+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,964 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T11:23:43.964+0000] {log.py:117} INFO - COMMIT
[2022-09-24T11:23:43.971+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,971 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T11:23:43.971+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T11:23:43.973+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,973 INFO sqlalchemy.engine.Engine INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T11:23:43.973+0000] {log.py:117} INFO - INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T11:23:43.973+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,973 INFO sqlalchemy.engine.Engine [generated in 0.00066s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T11:23:43.973+0000] {log.py:117} INFO - [generated in 0.00066s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T11:23:43.975+0000] {logging_mixin.py:117} INFO - 2022-09-24 11:23:43,975 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T11:23:43.975+0000] {log.py:117} INFO - COMMIT
[2022-09-24T11:23:43.976+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<<<<<<<<<<completed>>>>>>>>>>>>>>>>
[2022-09-24T11:23:43.976+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-09-24T11:23:43.989+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T112342, end_date=20220924T112343
[2022-09-24T11:23:44.027+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-09-24T11:23:44.062+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-09-24T12:49:50.799+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T12:49:50.810+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T12:49:50.810+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T12:49:50.810+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T12:49:50.810+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T12:49:50.823+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T12:49:50.828+0000] {standard_task_runner.py:54} INFO - Started process 306 to run task
[2022-09-24T12:49:50.831+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmpfykfdi24']
[2022-09-24T12:49:50.831+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask migrate
[2022-09-24T12:49:50.832+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T12:49:51.184+0000] {task_command.py:384} INFO - Running <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [running]> on host 1d69b603112e
[2022-09-24T12:49:51.263+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=isaaclucky88@gmail.com
AIRFLOW_CTX_DAG_OWNER=yishaktadele
AIRFLOW_CTX_DAG_ID=migrate_data
AIRFLOW_CTX_TASK_ID=migrate
AIRFLOW_CTX_EXECUTION_DATE=2022-09-23T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-09-23T00:00:00+00:00
[2022-09-24T12:49:51.264+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
  return func(*args, **kwargs)

[2022-09-24T12:49:51.273+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py:586: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.
  return _read(filepath_or_buffer, kwds)

[2022-09-24T12:49:51.281+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<start migrating data>>>>>>>>>>>>>>
[2022-09-24T12:49:51.291+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,291 INFO sqlalchemy.engine.Engine select pg_catalog.version()
[2022-09-24T12:49:51.291+0000] {log.py:117} INFO - select pg_catalog.version()
[2022-09-24T12:49:51.292+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,292 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T12:49:51.292+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T12:49:51.293+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,293 INFO sqlalchemy.engine.Engine select current_schema()
[2022-09-24T12:49:51.293+0000] {log.py:117} INFO - select current_schema()
[2022-09-24T12:49:51.294+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,294 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T12:49:51.294+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T12:49:51.295+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,295 INFO sqlalchemy.engine.Engine show standard_conforming_strings
[2022-09-24T12:49:51.295+0000] {log.py:117} INFO - show standard_conforming_strings
[2022-09-24T12:49:51.295+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,295 INFO sqlalchemy.engine.Engine [raw sql] {}
[2022-09-24T12:49:51.295+0000] {log.py:117} INFO - [raw sql] {}
[2022-09-24T12:49:51.298+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,298 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.298+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.299+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,299 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T12:49:51.299+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T12:49:51.299+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,299 INFO sqlalchemy.engine.Engine [generated in 0.00100s] {'name': 'traffic_data'}
[2022-09-24T12:49:51.299+0000] {log.py:117} INFO - [generated in 0.00100s] {'name': 'traffic_data'}
[2022-09-24T12:49:51.300+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,300 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T12:49:51.300+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T12:49:51.301+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,301 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.301+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.302+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,302 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T12:49:51.302+0000] {log.py:117} INFO - select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s
[2022-09-24T12:49:51.302+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,302 INFO sqlalchemy.engine.Engine [cached since 0.004171s ago] {'name': 'traffic_data'}
[2022-09-24T12:49:51.302+0000] {log.py:117} INFO - [cached since 0.004171s ago] {'name': 'traffic_data'}
[2022-09-24T12:49:51.305+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,305 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T12:49:51.305+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T12:49:51.309+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,309 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.309+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.310+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,310 INFO sqlalchemy.engine.Engine SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T12:49:51.310+0000] {log.py:117} INFO - SELECT c.relname FROM pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = %(schema)s AND c.relkind in ('r', 'p')
[2022-09-24T12:49:51.310+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,310 INFO sqlalchemy.engine.Engine [generated in 0.00123s] {'schema': 'public'}
[2022-09-24T12:49:51.310+0000] {log.py:117} INFO - [generated in 0.00123s] {'schema': 'public'}
[2022-09-24T12:49:51.314+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,314 INFO sqlalchemy.engine.Engine 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
[2022-09-24T12:49:51.314+0000] {log.py:117} INFO - 
            SELECT c.oid
            FROM pg_catalog.pg_class c
            LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
            WHERE (pg_catalog.pg_table_is_visible(c.oid))
            AND c.relname = %(table_name)s AND c.relkind in
            ('r', 'v', 'm', 'f', 'p')
        
[2022-09-24T12:49:51.314+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,314 INFO sqlalchemy.engine.Engine [generated in 0.00061s] {'table_name': 'traffic_data'}
[2022-09-24T12:49:51.314+0000] {log.py:117} INFO - [generated in 0.00061s] {'table_name': 'traffic_data'}
[2022-09-24T12:49:51.316+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,316 INFO sqlalchemy.engine.Engine 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
[2022-09-24T12:49:51.316+0000] {log.py:117} INFO - 
            SELECT a.attname,
              pg_catalog.format_type(a.atttypid, a.atttypmod),
              (
                SELECT pg_catalog.pg_get_expr(d.adbin, d.adrelid)
                FROM pg_catalog.pg_attrdef d
                WHERE d.adrelid = a.attrelid AND d.adnum = a.attnum
                AND a.atthasdef
              ) AS DEFAULT,
              a.attnotnull,
              a.attrelid as table_oid,
              pgd.description as comment,
              a.attgenerated as generated,
                              (SELECT json_build_object(
                    'always', a.attidentity = 'a',
                    'start', s.seqstart,
                    'increment', s.seqincrement,
                    'minvalue', s.seqmin,
                    'maxvalue', s.seqmax,
                    'cache', s.seqcache,
                    'cycle', s.seqcycle)
                FROM pg_catalog.pg_sequence s
                JOIN pg_catalog.pg_class c on s.seqrelid = c."oid"
                WHERE c.relkind = 'S'
                AND a.attidentity != ''
                AND s.seqrelid = pg_catalog.pg_get_serial_sequence(
                    a.attrelid::regclass::text, a.attname
                )::regclass::oid
                ) as identity_options                
            FROM pg_catalog.pg_attribute a
            LEFT JOIN pg_catalog.pg_description pgd ON (
                pgd.objoid = a.attrelid AND pgd.objsubid = a.attnum)
            WHERE a.attrelid = %(table_oid)s
            AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY a.attnum
        
[2022-09-24T12:49:51.316+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,316 INFO sqlalchemy.engine.Engine [generated in 0.00030s] {'table_oid': 16978}
[2022-09-24T12:49:51.316+0000] {log.py:117} INFO - [generated in 0.00030s] {'table_oid': 16978}
[2022-09-24T12:49:51.320+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,319 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
[2022-09-24T12:49:51.319+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               pg_catalog.format_type(t.typbasetype, t.typtypmod) as "attype",
               not t.typnotnull as "nullable",
               t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema"
            FROM pg_catalog.pg_type t
               LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
            WHERE t.typtype = 'd'
        
[2022-09-24T12:49:51.320+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,320 INFO sqlalchemy.engine.Engine [generated in 0.00074s] {}
[2022-09-24T12:49:51.320+0000] {log.py:117} INFO - [generated in 0.00074s] {}
[2022-09-24T12:49:51.322+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,322 INFO sqlalchemy.engine.Engine 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T12:49:51.322+0000] {log.py:117} INFO - 
            SELECT t.typname as "name",
               -- no enum defaults in 8.4 at least
               -- t.typdefault as "default",
               pg_catalog.pg_type_is_visible(t.oid) as "visible",
               n.nspname as "schema",
               e.enumlabel as "label"
            FROM pg_catalog.pg_type t
                 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
                 LEFT JOIN pg_catalog.pg_enum e ON t.oid = e.enumtypid
            WHERE t.typtype = 'e'
        ORDER BY "schema", "name", e.oid
[2022-09-24T12:49:51.323+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,323 INFO sqlalchemy.engine.Engine [generated in 0.00109s] {}
[2022-09-24T12:49:51.323+0000] {log.py:117} INFO - [generated in 0.00109s] {}
[2022-09-24T12:49:51.327+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,326 INFO sqlalchemy.engine.Engine 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
[2022-09-24T12:49:51.326+0000] {log.py:117} INFO - 
                SELECT a.attname
                FROM pg_attribute a JOIN (
                    SELECT unnest(ix.indkey) attnum,
                           generate_subscripts(ix.indkey, 1) ord
                    FROM pg_index ix
                    WHERE ix.indrelid = %(table_oid)s AND ix.indisprimary
                    ) k ON a.attnum=k.attnum
                WHERE a.attrelid = %(table_oid)s
                ORDER BY k.ord
            
[2022-09-24T12:49:51.327+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,327 INFO sqlalchemy.engine.Engine [generated in 0.00071s] {'table_oid': 16978}
[2022-09-24T12:49:51.327+0000] {log.py:117} INFO - [generated in 0.00071s] {'table_oid': 16978}
[2022-09-24T12:49:51.328+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,328 INFO sqlalchemy.engine.Engine 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
[2022-09-24T12:49:51.328+0000] {log.py:117} INFO - 
        SELECT conname
           FROM  pg_catalog.pg_constraint r
           WHERE r.conrelid = %(table_oid)s AND r.contype = 'p'
           ORDER BY 1
        
[2022-09-24T12:49:51.328+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,328 INFO sqlalchemy.engine.Engine [generated in 0.00026s] {'table_oid': 16978}
[2022-09-24T12:49:51.328+0000] {log.py:117} INFO - [generated in 0.00026s] {'table_oid': 16978}
[2022-09-24T12:49:51.330+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,330 INFO sqlalchemy.engine.Engine 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
[2022-09-24T12:49:51.330+0000] {log.py:117} INFO - 
          SELECT r.conname,
                pg_catalog.pg_get_constraintdef(r.oid, true) as condef,
                n.nspname as conschema
          FROM  pg_catalog.pg_constraint r,
                pg_namespace n,
                pg_class c

          WHERE r.conrelid = %(table)s AND
                r.contype = 'f' AND
                c.oid = confrelid AND
                n.oid = c.relnamespace
          ORDER BY 1
        
[2022-09-24T12:49:51.330+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,330 INFO sqlalchemy.engine.Engine [generated in 0.00027s] {'table': 16978}
[2022-09-24T12:49:51.330+0000] {log.py:117} INFO - [generated in 0.00027s] {'table': 16978}
[2022-09-24T12:49:51.331+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,331 INFO sqlalchemy.engine.Engine 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
[2022-09-24T12:49:51.331+0000] {log.py:117} INFO - 
              SELECT
                  i.relname as relname,
                  ix.indisunique, ix.indexprs,
                  a.attname, a.attnum, c.conrelid, ix.indkey::varchar,
                  ix.indoption::varchar, i.reloptions, am.amname,
                  pg_get_expr(ix.indpred, ix.indrelid),
                  ix.indnkeyatts as indnkeyatts
              FROM
                  pg_class t
                        join pg_index ix on t.oid = ix.indrelid
                        join pg_class i on i.oid = ix.indexrelid
                        left outer join
                            pg_attribute a
                            on t.oid = a.attrelid and a.attnum = ANY(ix.indkey)
                        left outer join
                            pg_constraint c
                            on (ix.indrelid = c.conrelid and
                                ix.indexrelid = c.conindid and
                                c.contype in ('p', 'u', 'x'))
                        left outer join
                            pg_am am
                            on i.relam = am.oid
              WHERE
                  t.relkind IN ('r', 'v', 'f', 'm', 'p')
                  and t.oid = %(table_oid)s
                  and ix.indisprimary = 'f'
              ORDER BY
                  t.relname,
                  i.relname
            
[2022-09-24T12:49:51.331+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,331 INFO sqlalchemy.engine.Engine [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.331+0000] {log.py:117} INFO - [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.334+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,334 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
[2022-09-24T12:49:51.334+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                cons.conkey as key,
                a.attnum as col_num,
                a.attname as col_name
            FROM
                pg_catalog.pg_constraint cons
                join pg_attribute a
                  on cons.conrelid = a.attrelid AND
                    a.attnum = ANY(cons.conkey)
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'u'
        
[2022-09-24T12:49:51.334+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,334 INFO sqlalchemy.engine.Engine [generated in 0.00028s] {'table_oid': 16978}
[2022-09-24T12:49:51.334+0000] {log.py:117} INFO - [generated in 0.00028s] {'table_oid': 16978}
[2022-09-24T12:49:51.335+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,335 INFO sqlalchemy.engine.Engine 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
[2022-09-24T12:49:51.335+0000] {log.py:117} INFO - 
            SELECT
                cons.conname as name,
                pg_get_constraintdef(cons.oid) as src
            FROM
                pg_catalog.pg_constraint cons
            WHERE
                cons.conrelid = %(table_oid)s AND
                cons.contype = 'c'
        
[2022-09-24T12:49:51.335+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,335 INFO sqlalchemy.engine.Engine [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.335+0000] {log.py:117} INFO - [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.336+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,336 INFO sqlalchemy.engine.Engine 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
[2022-09-24T12:49:51.336+0000] {log.py:117} INFO - 
            SELECT
                pgd.description as table_comment
            FROM
                pg_catalog.pg_description pgd
            WHERE
                pgd.objsubid = 0 AND
                pgd.objoid = %(table_oid)s
        
[2022-09-24T12:49:51.336+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,336 INFO sqlalchemy.engine.Engine [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.336+0000] {log.py:117} INFO - [generated in 0.00029s] {'table_oid': 16978}
[2022-09-24T12:49:51.337+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,337 INFO sqlalchemy.engine.Engine ROLLBACK
[2022-09-24T12:49:51.337+0000] {log.py:117} INFO - ROLLBACK
[2022-09-24T12:49:51.337+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,337 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.337+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.338+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,338 INFO sqlalchemy.engine.Engine 
DROP TABLE traffic_data
[2022-09-24T12:49:51.338+0000] {log.py:117} INFO - 
DROP TABLE traffic_data
[2022-09-24T12:49:51.338+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,338 INFO sqlalchemy.engine.Engine [no key 0.00025s] {}
[2022-09-24T12:49:51.338+0000] {log.py:117} INFO - [no key 0.00025s] {}
[2022-09-24T12:49:51.342+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,342 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T12:49:51.342+0000] {log.py:117} INFO - COMMIT
[2022-09-24T12:49:51.345+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,345 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.345+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.347+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,346 INFO sqlalchemy.engine.Engine 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)
[2022-09-24T12:49:51.346+0000] {log.py:117} INFO - 
CREATE TABLE traffic_data (
	id BIGINT, 
	track_id BIGINT, 
	" type" TEXT, 
	" traveled_d" FLOAT(53), 
	" avg_speed" FLOAT(53), 
	" lat" FLOAT(53), 
	" lon" FLOAT(53), 
	" speed" FLOAT(53), 
	" lon_acc" FLOAT(53), 
	" lat_acc" FLOAT(53), 
	" time" FLOAT(53)
)


[2022-09-24T12:49:51.347+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,347 INFO sqlalchemy.engine.Engine [no key 0.00034s] {}
[2022-09-24T12:49:51.347+0000] {log.py:117} INFO - [no key 0.00034s] {}
[2022-09-24T12:49:51.350+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,350 INFO sqlalchemy.engine.Engine CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T12:49:51.350+0000] {log.py:117} INFO - CREATE INDEX ix_traffic_data_id ON traffic_data (id)
[2022-09-24T12:49:51.350+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,350 INFO sqlalchemy.engine.Engine [no key 0.00029s] {}
[2022-09-24T12:49:51.350+0000] {log.py:117} INFO - [no key 0.00029s] {}
[2022-09-24T12:49:51.352+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,352 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T12:49:51.352+0000] {log.py:117} INFO - COMMIT
[2022-09-24T12:49:51.359+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,359 INFO sqlalchemy.engine.Engine BEGIN (implicit)
[2022-09-24T12:49:51.359+0000] {log.py:117} INFO - BEGIN (implicit)
[2022-09-24T12:49:51.360+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,360 INFO sqlalchemy.engine.Engine INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T12:49:51.360+0000] {log.py:117} INFO - INSERT INTO traffic_data (id, track_id, " type", " traveled_d", " avg_speed", " lat", " lon", " speed", " lon_acc", " lat_acc", " time") VALUES (%(id)s, %(track_id)s, %( type)s, %( traveled_d)s, %( avg_speed)s, %( lat)s, %( lon)s, %( speed)s, %( lon_acc)s, %( lat_acc)s, %( time)s)
[2022-09-24T12:49:51.361+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,360 INFO sqlalchemy.engine.Engine [generated in 0.00048s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T12:49:51.360+0000] {log.py:117} INFO - [generated in 0.00048s] ({'id': 0, 'track_id': 1, ' type': ' Car', ' traveled_d': 48.85, ' avg_speed': 9.770344, ' lat': 37.977391, ' lon': 23.737688, ' speed': 4.9178, ' lon_acc': 0.0518, ' lat_acc': -0.0299, ' time': 0.0}, {'id': 1, 'track_id': 2, ' type': ' Motorcycle', ' traveled_d': 98.09, ' avg_speed': 19.839417, ' lat': 37.977642, ' lon': 23.7374, ' speed': 16.9759, ' lon_acc': -0.0361, ' lat_acc': -0.0228, ' time': 0.0}, {'id': 2, 'track_id': 3, ' type': ' Motorcycle', ' traveled_d': 63.8, ' avg_speed': 18.228752, ' lat': 37.977997, ' lon': 23.737264, ' speed': 20.1906, ' lon_acc': -0.0795, ' lat_acc': -0.3395, ' time': 0.0}, {'id': 3, 'track_id': 4, ' type': ' Motorcycle', ' traveled_d': 145.72, ' avg_speed': 26.229014, ' lat': 37.978135, ' lon': 23.737072, ' speed': 2.7555, ' lon_acc': -0.0302, ' lat_acc': 0.0948, ' time': 0.0}, {'id': 4, 'track_id': 5, ' type': ' Motorcycle', ' traveled_d': 138.01, ' avg_speed': 24.841425, ' lat': 37.978134, ' lon': 23.737103, ' speed': 0.0, ' lon_acc': 0.0, ' lat_acc': 0.0, ' time': 0.0})
[2022-09-24T12:49:51.362+0000] {logging_mixin.py:117} INFO - 2022-09-24 12:49:51,362 INFO sqlalchemy.engine.Engine COMMIT
[2022-09-24T12:49:51.362+0000] {log.py:117} INFO - COMMIT
[2022-09-24T12:49:51.363+0000] {logging_mixin.py:117} INFO - <<<<<<<<<<<<<<<<<<<completed>>>>>>>>>>>>>>>>
[2022-09-24T12:49:51.363+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-09-24T12:49:51.374+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=migrate_data, task_id=migrate, execution_date=20220923T000000, start_date=20220924T124950, end_date=20220924T124951
[2022-09-24T12:49:51.404+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-09-24T12:49:51.428+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-09-24T13:08:10.952+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T13:08:11.010+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T13:08:11.011+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T13:08:11.011+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T13:08:11.011+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T13:08:11.085+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T13:08:11.093+0000] {standard_task_runner.py:54} INFO - Started process 379 to run task
[2022-09-24T13:08:11.097+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmp8kht7x2d']
[2022-09-24T13:08:11.097+0000] {standard_task_runner.py:83} INFO - Job 7: Subtask migrate
[2022-09-24T13:08:11.101+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T13:08:43.860+0000] {timeout.py:68} ERROR - Process timed out, PID: 379
[2022-09-24T13:08:43.863+0000] {dagbag.py:330} ERROR - Failed to import: /opt/***/dags/migrate.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/migrate.py", line 3, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 23, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/pyarrow.py", line 6, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.7/site-packages/pyarrow/__init__.py", line 63, in <module>
    import pyarrow.lib as _lib
  File "<frozen importlib._bootstrap>", line 416, in parent
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/***/dags/migrate.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://***.apache.org/docs/apache-***/2.4.0/best-practices.html#top-level-python-code
* https://***.apache.org/docs/apache-***/2.4.0/best-practices.html#reducing-dag-complexity, PID: 379
[2022-09-24T13:08:43.899+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task migrate (Dag 'migrate_data' could not be found; either it does not exist or it failed to parse.; 379)
[2022-09-24T13:08:43.959+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-09-24T13:08:44.010+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-09-24T13:49:25.592+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T13:49:25.630+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: migrate_data.migrate scheduled__2022-09-23T00:00:00+00:00 [queued]>
[2022-09-24T13:49:25.632+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T13:49:25.633+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2022-09-24T13:49:25.634+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-09-24T13:49:25.687+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): migrate> on 2022-09-23 00:00:00+00:00
[2022-09-24T13:49:25.702+0000] {standard_task_runner.py:54} INFO - Started process 916 to run task
[2022-09-24T13:49:25.735+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'migrate_data', 'migrate', 'scheduled__2022-09-23T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/migrate.py', '--cfg-path', '/tmp/tmpq2fq3rxs']
[2022-09-24T13:49:25.736+0000] {standard_task_runner.py:83} INFO - Job 7: Subtask migrate
[2022-09-24T13:49:25.738+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/migrate.py
[2022-09-24T13:49:59.109+0000] {timeout.py:68} ERROR - Process timed out, PID: 916
[2022-09-24T13:50:00.526+0000] {dagbag.py:330} ERROR - Failed to import: /opt/***/dags/migrate.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/migrate.py", line 4, in <module>
    from airflow.providers.postgres.operators.postgres import PostgresOperator
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 30, in <module>
    class PostgresOperator(BaseOperator):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 434, in __new__
    new_cls.__init__ = cls._apply_defaults(new_cls.__init__)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 328, in _apply_defaults
    sig_cache = signature(func)
  File "/usr/local/lib/python3.7/inspect.py", line 3083, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped)
  File "/usr/local/lib/python3.7/inspect.py", line 2833, in from_callable
    follow_wrapper_chains=follow_wrapped)
  File "/usr/local/lib/python3.7/inspect.py", line 2284, in _signature_from_callable
    return _signature_from_function(sigcls, obj)
  File "/usr/local/lib/python3.7/inspect.py", line 2157, in _signature_from_function
    for offset, name in enumerate(positional[non_default_count:]):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/***/dags/migrate.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://***.apache.org/docs/apache-***/2.4.0/best-practices.html#top-level-python-code
* https://***.apache.org/docs/apache-***/2.4.0/best-practices.html#reducing-dag-complexity, PID: 916
[2022-09-24T13:50:01.596+0000] {base_job.py:232} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 204, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2961, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3039, in _merge
    options=options,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2775, in get
    identity_token=identity_token,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2878, in _get_impl
    load_options=load_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 534, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1688, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1530, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3197, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3276, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3247, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2101, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3243, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 310, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 868, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 476, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 256, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 371, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 666, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 207, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 590, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 584, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2022-09-24T13:50:13.018+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task migrate (Dag 'migrate_data' could not be found; either it does not exist or it failed to parse.; 916)
[2022-09-24T13:50:14.442+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-09-24T13:50:14.607+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
